{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file contains code for data wrangling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import socket\n",
    "import boto3\n",
    "import logging\n",
    "from logging import Logger\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "from boto3.s3.transfer import S3Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is not present for today on s3!!!!!\n"
     ]
    }
   ],
   "source": [
    "log_time = datetime.datetime.now().strftime(\"%d%m%Y_%M%S\")\n",
    "\n",
    "logging.basicConfig(filename = log_time+'.txt',\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "with open('configWrangle.json') as json_file:\n",
    "    json_txt =json.load(json_file)\n",
    "AWS_ACCESS_KEY = json_txt[\"AWSAccess\"]\n",
    "AWS_SECRET_KEY = json_txt[\"AWSSecret\"]\n",
    "State=json_txt[\"state\"]\n",
    "St_Id = json_txt[\"Station_Id\"]\n",
    "RawData_Link = json_txt[\"rawData\"]\n",
    "\n",
    "conn = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)\n",
    "transfer = S3Transfer(conn)\n",
    "\n",
    "current_date = RawData_Link[-23:-15]\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for key in conn.list_objects(Bucket='Team6ILAssignment01')['Contents']:\n",
    "    filenames.append(key['Key'])\n",
    "        \n",
    "datelist = [filedate[3:11] for filedate in filenames]\n",
    "\n",
    "actual_file = State + '_' + current_date + '_' + St_Id + '.csv'\n",
    "actual_file_clean = State + '_' + current_date + '_' + St_Id + '_clean' + '.csv'\n",
    "target_directory = '/usr/src/Assignment1'\n",
    "\n",
    "if current_date in datelist:\n",
    "    if actual_file_clean not in filenames:\n",
    "        print(\"File is present for today on s3. Downloading today's file!!!!!\")\n",
    "        logging.warning(\"File is present for today on s3. Downloading today's file!!!!!\")\n",
    "    \n",
    "        transfer.download_file('Team6ILAssignment01', actual_file, os.path.join(target_directory, actual_file))\n",
    "        print('File downloaded successfully!!!!!')\n",
    "        logging.warning(\"File downloaded successfully!!!!!\")\n",
    "    \n",
    "        print('Starting Data Wrangling process!!!!!')\n",
    "        logging.warning(\"Starting Data Wrangling process!!!!!\")\n",
    "    \n",
    "        csv_data_df =pd.read_csv(actual_file,encoding='ISO-8859-1',\n",
    "                                 usecols=[0, 1,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],low_memory=False)\n",
    "    \n",
    "        cols = ['HOURLYVISIBILITY','HOURLYDRYBULBTEMPF','HOURLYWETBULBTEMPF','HOURLYDewPointTempF','HOURLYWindDirection',\n",
    "                'HOURLYStationPressure','HOURLYPressureChange','HOURLYSeaLevelPressure','HOURLYPrecip','HOURLYAltimeterSetting'\n",
    "                ,'HOURLYDRYBULBTEMPC','HOURLYWETBULBTEMPC','HOURLYWindSpeed','HOURLYRelativeHumidity','HOURLYDewPointTempC']\n",
    "    \n",
    "        csv_data_df[cols]=csv_data_df[cols].astype(str)\n",
    "        csv_data_df[cols]=csv_data_df[cols].applymap(lambda x: re.sub(r'[^0-9^\\-\\.]+', '', x)).replace('', np.nan).astype('float64')\n",
    "    \n",
    "        temp_df = csv_data_df[['HOURLYPressureTendency']].copy()\n",
    "        x=temp_df[\"HOURLYPressureTendency\"].astype('float64').mean()\n",
    "        csv_data_df[\"HOURLYPressureTendency\"]=csv_data_df[\"HOURLYPressureTendency\"].fillna(x)\n",
    "    \n",
    "        csv_data_df[\"HOURLYPressureChange\"]=csv_data_df[\"HOURLYPressureChange\"].replace(0.0, np.nan)\n",
    "        x=csv_data_df[\"HOURLYPressureChange\"].astype('float64').mean()\n",
    "        csv_data_df[\"HOURLYPressureChange\"]=csv_data_df[\"HOURLYPressureChange\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[csv_data_df[\"HOURLYVISIBILITY\"]!=0]\n",
    "        x=temp_df[\"HOURLYVISIBILITY\"].mean()\n",
    "        csv_data_df[\"HOURLYVISIBILITY\"]=csv_data_df[\"HOURLYVISIBILITY\"].replace(0.0,x)\n",
    "        csv_data_df[\"HOURLYVISIBILITY\"]=csv_data_df[\"HOURLYVISIBILITY\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[csv_data_df[\"HOURLYDRYBULBTEMPF\"]!=0]\n",
    "        x=temp_df[\"HOURLYDRYBULBTEMPF\"].mean()\n",
    "        csv_data_df[\"HOURLYDRYBULBTEMPF\"]=csv_data_df[\"HOURLYDRYBULBTEMPF\"].replace(0.0,x)\n",
    "        csv_data_df[\"HOURLYDRYBULBTEMPF\"]=csv_data_df[\"HOURLYDRYBULBTEMPF\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[csv_data_df[\"HOURLYDRYBULBTEMPC\"]!=0]\n",
    "        x=temp_df[\"HOURLYDRYBULBTEMPC\"].mean()\n",
    "        csv_data_df[\"HOURLYDRYBULBTEMPC\"]=csv_data_df[\"HOURLYDRYBULBTEMPC\"].replace(0.0,x)\n",
    "        csv_data_df[\"HOURLYDRYBULBTEMPC\"]=csv_data_df[\"HOURLYDRYBULBTEMPC\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[['HOURLYWETBULBTEMPF']].copy()\n",
    "        x=temp_df[\"HOURLYWETBULBTEMPF\"].astype('float64').mean()\n",
    "        csv_data_df[\"HOURLYWETBULBTEMPF\"]=csv_data_df[\"HOURLYWETBULBTEMPF\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[csv_data_df[\"HOURLYWETBULBTEMPC\"]!=0]\n",
    "        temp_df[\"HOURLYWETBULBTEMPC\"] = temp_df[\"HOURLYWETBULBTEMPC\"].replace('*',np.nan)\n",
    "        x=temp_df[\"HOURLYWETBULBTEMPC\"].mean()\n",
    "        csv_data_df[\"HOURLYWETBULBTEMPC\"]=csv_data_df[\"HOURLYWETBULBTEMPC\"].replace(0.0,x)\n",
    "        csv_data_df[\"HOURLYWETBULBTEMPC\"]=csv_data_df[\"HOURLYWETBULBTEMPC\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[csv_data_df[\"HOURLYDewPointTempF\"]!=0]\n",
    "        x=temp_df[\"HOURLYDewPointTempF\"].mean()\n",
    "        csv_data_df[\"HOURLYDewPointTempF\"]=csv_data_df[\"HOURLYDewPointTempF\"].replace(0.0,x)\n",
    "        csv_data_df[\"HOURLYDewPointTempF\"]=csv_data_df[\"HOURLYDewPointTempF\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[csv_data_df[\"HOURLYDewPointTempC\"]!=0]\n",
    "        x=temp_df[\"HOURLYDewPointTempC\"].mean()\n",
    "        csv_data_df[\"HOURLYDewPointTempC\"]=csv_data_df[\"HOURLYDewPointTempC\"].replace(0.0,x)\n",
    "        csv_data_df[\"HOURLYDewPointTempC\"]=csv_data_df[\"HOURLYDewPointTempC\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[['HOURLYRelativeHumidity']].copy()\n",
    "        x=temp_df[\"HOURLYRelativeHumidity\"].astype('float64').mean()\n",
    "        csv_data_df[\"HOURLYRelativeHumidity\"]=csv_data_df[\"HOURLYRelativeHumidity\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[csv_data_df[\"HOURLYWindSpeed\"]!=0]\n",
    "        x=temp_df[\"HOURLYWindSpeed\"].mean()\n",
    "        csv_data_df[\"HOURLYWindSpeed\"]=csv_data_df[\"HOURLYWindSpeed\"].replace(0.0,x)\n",
    "        csv_data_df[\"HOURLYWindSpeed\"]=csv_data_df[\"HOURLYWindSpeed\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[['HOURLYWindDirection']].copy()\n",
    "        x=temp_df[\"HOURLYWindDirection\"].astype('float64').mean()\n",
    "        csv_data_df[\"HOURLYWindDirection\"]=csv_data_df[\"HOURLYWindDirection\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[['HOURLYWindGustSpeed']].copy()\n",
    "        temp_df[\"HOURLYWindGustSpeed\"] = temp_df[\"HOURLYWindGustSpeed\"].replace('*',np.nan)\n",
    "        x=temp_df[\"HOURLYWindGustSpeed\"].astype('float64').mean()\n",
    "        csv_data_df[\"HOURLYWindGustSpeed\"]=csv_data_df[\"HOURLYWindGustSpeed\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[csv_data_df[\"HOURLYStationPressure\"]!=0]\n",
    "        x=temp_df[\"HOURLYStationPressure\"].mean()\n",
    "        csv_data_df[\"HOURLYStationPressure\"]=csv_data_df[\"HOURLYStationPressure\"].replace(0.0,x)\n",
    "        csv_data_df[\"HOURLYStationPressure\"]=csv_data_df[\"HOURLYStationPressure\"].fillna(x)\n",
    "\n",
    "        temp_df = csv_data_df[csv_data_df[\"HOURLYSeaLevelPressure\"]!=0]\n",
    "        x=temp_df[\"HOURLYSeaLevelPressure\"].mean()\n",
    "        csv_data_df[\"HOURLYSeaLevelPressure\"]=csv_data_df[\"HOURLYSeaLevelPressure\"].replace(0.0,x)\n",
    "        csv_data_df[\"HOURLYSeaLevelPressure\"]=csv_data_df[\"HOURLYSeaLevelPressure\"].fillna(x)\n",
    "    \n",
    "        with open(actual_file_clean, 'w') as myfile:\n",
    "            myfile.write(csv_data_df.to_csv(index=False))\n",
    "    \n",
    "        os.unlink(actual_file)\n",
    "    \n",
    "        print('Data Wrangling process completed!!!!!')\n",
    "        logging.warning(\"Data Wrangling process completed!!!!!\")\n",
    "        \n",
    "    else:\n",
    "        print('Data Wrangling process is already completed for today!!!!!')\n",
    "        logging.warning(\"Data Wrangling process is already completed for today!!!!!\")\n",
    "    \n",
    "else:\n",
    "    print('File is not present for today on s3!!!!!')\n",
    "    logging.warning(\"File is not present for today on s3!!!!!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File upload started to s3!!!!! \n",
      "\n",
      "File uploaded to s3!!!!! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sync_to_s3(target_dir, bucket_name, AWS_ACCESS_KEY, AWS_SECRET_KEY):\n",
    "    if not os.path.isdir(target_dir):\n",
    "        raise ValueError('target_dir %r not found.' % target_dir)\n",
    "\n",
    "    conn = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)\n",
    "    transfer = S3Transfer(conn)\n",
    "\n",
    "    response = conn.list_buckets()\n",
    "    existent = []\n",
    "    for bucket in response[\"Buckets\"]:\n",
    "        existent.append(bucket['Name'])\n",
    "        \n",
    "    filename = None\n",
    "    file_list = os.listdir(target_dir)\n",
    "    \n",
    "    if actual_file_clean in file_list:\n",
    "        filename = actual_file_clean    \n",
    "        \n",
    "        if bucket_name in existent:\n",
    "            filenames = []\n",
    "            for key in conn.list_objects(Bucket=bucket_name)['Contents']:\n",
    "                filenames.append(key['Key'])\n",
    "        \n",
    "            if filename not in filenames:\n",
    "                print('File upload started to s3!!!!!', '\\n')\n",
    "                transfer.upload_file(os.path.join(target_dir, filename), bucket_name, filename)\n",
    "                print('File uploaded to s3!!!!!','\\n')\n",
    "                logging.warning(\"File uploaded to s3!!!!!\")\n",
    "            \n",
    "            else:\n",
    "                logging.warning(\"File already exist on s3!!!!\")\n",
    "                print('File already present on s3!!!!!', '\\n')\n",
    "            \n",
    "        else:\n",
    "            conn.create_bucket(Bucket=bucket_name)\n",
    "            print('File upload started to s3!!!!!', '\\n')\n",
    "            logging.warning(\"New file already present!!!!\")\n",
    "            transfer.upload_file(os.path.join(target_dir, filename), bucket_name, filename)\n",
    "            print('File uploaded to s3!!!!!','\\n')\n",
    "            logging.warning(\"File uploaded to s3!!!!!\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Today's Data file is either not present or wrangling is already been completed. CHeck previous msg!!!!!\")\n",
    "        logging.warning(\"Today's Data file is either not present or wrangling is already been completed. CHeck previous msg!!!!!\")\n",
    "        \n",
    "sync_to_s3('/usr/src/Assignment1', 'Team6ILAssignment01', AWS_ACCESS_KEY, AWS_SECRET_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
